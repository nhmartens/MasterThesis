{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4338019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "\n",
    "check_gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "print('GPU is', 'available' if check_gpu else 'NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aec132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a27f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_10_lvls(df):\n",
    "    prices=[]\n",
    "    quantities = []\n",
    "    if df['type'].unique()[0] == 'a':\n",
    "        index = df['price'].sort_values(ascending=True).index\n",
    "        for i in index:\n",
    "            if len(prices) < 10:\n",
    "                if df['price'][i] not in prices:\n",
    "                    prices.append(df['price'][i])\n",
    "                    quantities.append(df['amount'][i])\n",
    "                else:\n",
    "                    quantities[-1] += df['amount'][i]\n",
    "            else:\n",
    "                break\n",
    "        if len(prices) < 10:\n",
    "            decimals = len(str(prices[-1]).split('.')[1]) if len(str(prices[-1]).split('.'))==2 else 0\n",
    "            while len(prices) < 10:\n",
    "                increment = 10**-decimals\n",
    "                prices.append(round(prices[-1]+increment, decimals))\n",
    "                quantities.append(0)\n",
    "                \n",
    "    elif df['type'].unique()[0] == 'b':\n",
    "        index = df['price'].sort_values(ascending=False).index\n",
    "        for i in index:\n",
    "            if len(prices) < 10:\n",
    "                if df['price'][i] not in prices:\n",
    "                    prices.append(df['price'][i])\n",
    "                    quantities.append(df['amount'][i])\n",
    "                else:\n",
    "                    quantities[-1] += df['amount'][i]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if len(prices) < 10:\n",
    "            decimals = len(str(prices[-1]).split('.')[1]) if len(str(prices[-1]).split('.'))==2 else 0\n",
    "            while len(prices) < 10:\n",
    "                increment = 10**-decimals\n",
    "                prices.append(round(prices[-1]-increment, decimals))\n",
    "                quantities.append(0)\n",
    "    #return pd.Series({'price': prices, 'amount': quantities})\n",
    "    return pd.DataFrame({'price': prices, 'amount': quantities})\n",
    "    \n",
    "    #return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d27baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object and props[col].dtype != 'datetime64[ns]' and props[col].dtype != 'category':  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            #print(\"******************************\")\n",
    "            #print(\"Column: \",col)\n",
    "            #print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                with pd.option_context('mode.chained_assignment', None):\n",
    "                    props.loc[:,col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props.loc[:,col].fillna(0).astype(np.int64)\n",
    "            result = (props.loc[:,col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    with pd.option_context('mode.chained_assignment', None):\n",
    "                        if mx < 255:\n",
    "                            props.loc[:,col] = props.loc[:,col].astype(np.uint8)\n",
    "                        elif mx < 65535:\n",
    "                            props.loc[:,col] = props.loc[:,col].astype(np.uint16)\n",
    "                        elif mx < 4294967295:\n",
    "                            props.loc[:,col] = props.loc[:,col].astype(np.uint32)\n",
    "                        else:\n",
    "                            props.loc[:,col] = props.loc[:,col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props.loc[:,col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props.loc[:,col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props.loc[:,col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props.loc[:,col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                with pd.option_context('mode.chained_assignment', None):\n",
    "                    props.loc[:,col] = props.loc[:,col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            #print(\"dtype after: \",props[col].dtype)\n",
    "            #print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    \n",
    "    return props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b1b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = ['BTCUSDT', 'BTCUSDC', 'DOGEUSDT', 'ETHBTC', 'ETHUSDC', 'ETHUSDT', 'LINKETH', 'LINKUSDT', 'LTCUSDC', 'LTCUSDT', 'USDCUSDT','XRPETH', 'XRPUSDC', 'XRPUSDT']\n",
    "label_lookback = [2, 5, 10, 15, 20, 30, 50, 60, 100]\n",
    "label_alpha = 0.0002\n",
    "dirname = os.path.dirname(os.getcwd())\n",
    "raw_data_dir = os.path.join(dirname, \"Data\", \"Raw_Data\")\n",
    "cleaned_data_dir = os.path.join(dirname, \"Data\", \"Clean_Data\")\n",
    "norm_data_dir = os.path.join(dirname, \"Data\", \"Norm_Data\")\n",
    "\n",
    "def clean_file(raw_data_folder_path):\n",
    "    for raw_file in os.listdir(raw_data_folder_path):\n",
    "        if raw_file[-3:] == \".gz\":\n",
    "            pair_name = [pair for pair in pair_list if pair in raw_file][0]\n",
    "            new_file = os.path.join(cleaned_data_dir, pair_name, raw_file.replace(\".gz\",\"\"))\n",
    "            if not os.path.exists(new_file):\n",
    "                print(raw_file)\n",
    "                df = pd.read_csv(os.path.join(raw_data_folder_path,raw_file), compression=\"gzip\", on_bad_lines='skip')\n",
    "\n",
    "                df = df.groupby(['date','type']).apply(lambda x: identify_10_lvls(x)).reset_index()\n",
    "                df = df.groupby('date', group_keys=False).apply(lambda x: x.sort_values(['type','price'], ascending=[True, False])).reset_index(drop=True)\n",
    "                df['level_2'] = df['level_2']+1\n",
    "                #df['date'] = df['date'].apply(lambda x: datetime.fromtimestamp(x/1000))\n",
    "                df['date'] = df['date'].apply(lambda x: datetime.utcfromtimestamp(x/1000))\n",
    "                df = df.rename(columns={\"level_2\": \"level\"})\n",
    "                df = df[['type', 'price', 'amount', 'level', 'date']]\n",
    "\n",
    "                # The mid_price is only calculated after normalisation\n",
    "                # mid_price = df[df['level']==1].groupby('date').apply(lambda x: x['price'].mean()).reset_index(name='mid_price')\n",
    "                # df = df.merge(mid_price)\n",
    "                df.to_csv(new_file, index=False)\n",
    "\n",
    "def z_score(df):\n",
    "    unique_days = df.ymd.unique()\n",
    "    unique_days.sort()\n",
    "    means_stds = pd.DataFrame(index = unique_days, columns = ['mean_p', 'std_p', 'mean_a', 'std_a', 'obs', 'first_obs', 'last_obs'])\n",
    "    for day in unique_days:\n",
    "        daysToInclude = [day - timedelta(days = d) for d in range(1,6) if day -timedelta(days = d) in unique_days]\n",
    "        if len(daysToInclude) == 5:\n",
    "            subset = df[np.isin(df['ymd'], daysToInclude)]\n",
    "            subset = subset.reset_index(drop=True)\n",
    "            means_stds.loc[day, 'mean_p'] = subset.price.mean()\n",
    "            means_stds.loc[day, 'std_p'] = subset.price.std()\n",
    "            means_stds.loc[day, 'mean_a'] = subset.amount.mean()\n",
    "            means_stds.loc[day, 'std_a'] = subset.amount.std()\n",
    "            #means_stds.loc[day, 'obs'] = subset.shape[0]\n",
    "            #means_stds.loc[day, 'first_obs'] = subset.loc[0, 'price']\n",
    "            #means_stds.loc[day, 'last_obs'] = subset.loc[subset.shape[0]-1,'price']\n",
    "            \n",
    "    df = pd.merge(df, means_stds, right_index=True, left_on='ymd')\n",
    "    df['price_norm'] = (df['price'] - df['mean_p']) / df['std_p']\n",
    "    df['amount_norm'] = (df['amount'] - df['mean_a']) / df['std_a']\n",
    "    \n",
    "    # applied to not normalized prices, as otherwise labels will be wrong due to negative signs for some mid prices\n",
    "    \n",
    "    mid_price = df[df['level']==1].groupby('date').apply(lambda x: x['price'].mean()).reset_index(name='mid_price')\n",
    "    #mid_price = df[df['level']==1].groupby('date').apply(lambda x: x['price_norm'].mean()).reset_index(name='mid_price')\n",
    "    \n",
    "    df = df.merge(mid_price)\n",
    "        \n",
    "    return pd.DataFrame({'date': df.date, 'day': df.ymd, 'type': df.type, 'level': df.level, 'price_norm': df.price_norm, 'amount_norm': df.amount_norm, 'mid_price': df['mid_price']})\n",
    "             \n",
    "def dummy(dat):\n",
    "    return 1\n",
    "           \n",
    "def normalize(clean_data_folder_path, replace_files = 0):\n",
    "    files_sorted = os.listdir(clean_data_folder_path)\n",
    "    files_sorted.sort()\n",
    "    for file in [file for file in files_sorted if file[-4:] == \".par\"]:\n",
    "        pair_name = [pair for pair in pair_list if pair in file][0]\n",
    "        new_file = os.path.join(norm_data_dir, pair_name+'.feather')\n",
    "        if not os.path.exists(new_file) or replace_files:\n",
    "            print(file)\n",
    "            final_df = pd.read_parquet(os.path.join(clean_data_folder_path, file))\n",
    "            final_df['date'] = final_df['date'].astype('datetime64[ns]')\n",
    "            final_df['ymd'] = final_df['date'].apply(lambda x: x.date())\n",
    "            final_df = pd.melt(final_df, id_vars=['date', 'level', 'ymd', 'ask_amount', 'bid_amount'], value_name='price', var_name='type')\n",
    "            final_df = final_df.sort_values(['date', 'price'], ascending=[True, False])\n",
    "            final_df['type'] = np.where(final_df['type']=='ask_price', 'a', 'b')\n",
    "            final_df['amount'] = np.where(final_df['type']=='a', final_df['ask_amount'] , final_df['bid_amount'])\n",
    "            final_df = final_df.drop(columns=['ask_amount', 'bid_amount'])\n",
    "    \n",
    "            norm_df = final_df.groupby(dummy).apply(lambda x: z_score(x))\n",
    "            norm_df = norm_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "            output = norm_df.set_index(['date', 'day', 'level', 'type', 'mid_price'], drop = True).unstack(['level', 'type'])\n",
    "            output = output.sort_index(axis=1,level=[1,2,0],ascending=[True,True, False])\n",
    "            output.columns = output.columns.get_level_values(2) + '_' + [str(i) for i in output.columns.get_level_values(1)]  + '_' + output.columns.get_level_values(0)\n",
    "            output = output.reset_index()\n",
    "    \n",
    "            output.loc[:,~output.columns.isin(['date', 'day', 'mid_price'])] = output.loc[:,~output.columns.isin(['date', 'day', 'mid_price'])].astype(float)\n",
    "\n",
    "    \n",
    "            # Create labels\n",
    "            for k in label_lookback:\n",
    "                output[f\"label_k_{k}\"] = (output.rolling(k, closed='left').mid_price.mean().shift(-(k+1)) - output['mid_price']) / output['mid_price']\n",
    "                output[f\"label_k_{k}\"] = np.where(output[f\"label_k_{k}\"] >= label_alpha, 1, np.where(output[f\"label_k_{k}\"] <= -label_alpha, 3, 2))\n",
    "                output[f\"label_k_{k}\"] = output[f\"label_k_{k}\"].astype('category')\n",
    "\n",
    "            output = output[output['a_1_price_norm'].notna()].reset_index(drop = True)\n",
    "            output = reduce_mem_usage(output)\n",
    "\n",
    "            output.to_feather(new_file)\n",
    "    \n",
    "    #return output\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11743565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7dc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the raw data in a certain folder\n",
    "# In case of EOF Error (unexpected end of file): gzcat <file_name> | less > file.csv\n",
    "# Then gzip the csv file and rename it to the old name: command to gzip: gzip file.csv\n",
    "\n",
    "# gzip -dc test.csv.gz > file.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6a1c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binance-BTCUSDC_full.par\n",
      "Memory usage of properties dataframe is : 680.7682132720947  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  364.49121284484863  MB\n",
      "This is  53.541162136952764 % of the initial size\n",
      "Binance-BTCUSDT_full.par\n",
      "Memory usage of properties dataframe is : 684.4319429397583  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  366.45281314849854  MB\n",
      "This is  53.54116167847424 % of the initial size\n",
      "Binance-DOGEUSDT_full.par\n",
      "Memory usage of properties dataframe is : 544.0568628311157  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  291.29448413848877  MB\n",
      "This is  53.54118365912635 % of the initial size\n",
      "Binance-ETHBTC_full.par\n",
      "Memory usage of properties dataframe is : 680.7338752746582  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  364.47282791137695  MB\n",
      "This is  53.54116214127316 % of the initial size\n",
      "Binance-ETHUSDC_full.par\n",
      "Memory usage of properties dataframe is : 687.040620803833  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  367.8495273590088  MB\n",
      "This is  53.54116135500507 % of the initial size\n",
      "Binance-ETHUSDT_full.par\n",
      "Memory usage of properties dataframe is : 689.2934627532959  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  369.0557231903076  MB\n",
      "This is  53.54116107762883 % of the initial size\n",
      "Binance-LINKETH_full.par\n",
      "Memory usage of properties dataframe is : 685.8687524795532  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  367.22209644317627  MB\n",
      "This is  53.541161500009245 % of the initial size\n",
      "Binance-LINKUSDT_full.par\n",
      "Memory usage of properties dataframe is : 676.7156562805176  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  362.3214302062988  MB\n",
      "This is  53.54116264987173 % of the initial size\n",
      "Binance-LTCUSDC_full.par\n",
      "Memory usage of properties dataframe is : 632.9128274917603  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  338.8689241409302  MB\n",
      "This is  53.541168613041236 % of the initial size\n",
      "Binance-LTCUSDT_full.par\n",
      "Memory usage of properties dataframe is : 734.1570663452148  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  393.07617950439453  MB\n",
      "This is  53.54115590839557 % of the initial size\n",
      "Binance-USDCUSDT_full.par\n",
      "Memory usage of properties dataframe is : 684.7382917404175  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  366.61683559417725  MB\n",
      "This is  53.54116164036007 % of the initial size\n",
      "Binance-XRPETH_full.par\n",
      "Memory usage of properties dataframe is : 24.230751991271973  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  12.97398853302002  MB\n",
      "This is  53.54348283409986 % of the initial size\n",
      "Binance-XRPUSDC_full.par\n",
      "Memory usage of properties dataframe is : 670.1389198303223  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  358.80017471313477  MB\n",
      "This is  53.54116349547079 % of the initial size\n",
      "Binance-XRPUSDT_full.par\n",
      "Memory usage of properties dataframe is : 733.8113298416138  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  392.89106845855713  MB\n",
      "This is  53.54115594581498 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "# Normalize the cleaned data in a certain folder\n",
    "clean_data_folder_path = cleaned_data_dir\n",
    "normalize(clean_data_folder_path, replace_files = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f21b2515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da5387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
